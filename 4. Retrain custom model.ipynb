{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import object_detection\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate custom model & desired checkpoint from training\n",
    "CUSTOM_MODEL = 'my_centernet_hg104_1024_5_v2'\n",
    "PRETRAINED_CUSTOM_MODEL = 'my_centernet_hg104_1024_5'\n",
    "CUSTOM_CHECKPOINT = 'ckpt-21'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "# indicate name of folder of new test images\n",
    "NEW_TEST_IMGS = 'test'#'supersaturation_0.16_cropJG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations',CUSTOM_MODEL),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'IMAGE_PATH_TRAIN': os.path.join('Tensorflow', 'workspace','images','train'),\n",
    "    'IMAGE_PATH_TEST': os.path.join('Tensorflow', 'workspace','images','test'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'PRETRAINED_CUSTOM_MODEL_PATH': os.path.join('Tensorflow', 'workspace','models',PRETRAINED_CUSTOM_MODEL),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',PRETRAINED_CUSTOM_MODEL), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL, 'tfliteexport'),\n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PRETRAINED_PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', PRETRAINED_CUSTOM_MODEL, 'pipeline.config'),\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "# creating folders\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "#!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT PATH: copy pipeline.config (pretrained model) into new config folder\n",
    "if os.name =='posix':\n",
    "    !cp {files['PRETRAINED_PIPELINE_CONFIG']} {files['PIPELINE_CONFIG']}\n",
    "if os.name == 'nt':\n",
    "    !copy {files['PRETRAINED_PIPELINE_CONFIG']} {files['PIPELINE_CONFIG']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TFRecord file\n",
    "# --> train and test record file within annotations path\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config (copy of pretrained custom model config file)\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG_NEW'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config (new/modified config file)\n",
    "configs_test = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG_NEW'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'Bubble', 'id':1}]\n",
    "\n",
    "# write into label map file\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "# MODIFY PIPELINE.CONFIG\n",
    "# modify pipeline.config for personal use case (num classes, set paths etc.)\n",
    "pipeline_config.train_config.batch_size = 1\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_CUSTOM_MODEL_PATH'],'checkpoint',CUSTOM_CHECKPOINT)\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tensorflow/workspace/annotations/my_faster_rcnn_resnet152_v1_1024/test.record']\n"
     ]
    }
   ],
   "source": [
    "print([os.path.join(paths['ANNOTATION_PATH'], 'test.record')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new pipeline config (to model folder)\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "# dfile: accessing the file ('wb'= writing to file in binary mode)                                                                                                                                                                                                     \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG_NEW'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config (new/modified config file)\n",
    "configs_new = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG_NEW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 6. Train the model\n",
    "Before Training, my_model directory must be empty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# test if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# check GPU use\n",
    "# watch -n0.1 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG_NEW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_faster_rcnn_resnet152_v1_1024 --pipeline_config_path=Tensorflow/workspace/models/my_faster_rcnn_resnet152_v1_1024/pipeline.config --num_train_steps=10000\n"
     ]
    }
   ],
   "source": [
    "# to see training status, copy command to prompt and run from there\n",
    "# (from tfodCourse directory and with activated environment)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 7. Evaluate the Model\n",
    "Calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG_NEW'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_faster_rcnn_resnet152_v1_1024 --pipeline_config_path=Tensorflow/workspace/models/my_faster_rcnn_resnet152_v1_1024/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_faster_rcnn_resnet152_v1_1024\n"
     ]
    }
   ],
   "source": [
    "# command can be run from prompt to see progress\n",
    "print(command)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "32209f67b09482863979d97556c828a1a8b5b7e3b0ad73f4601c05d63f9a006e"
  },
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
